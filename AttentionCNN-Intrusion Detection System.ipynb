{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8296cf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 20:15:10.733504: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Softmax, Multiply, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "all_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bf876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.4\n",
      "1.19.5\n",
      "3.4.3\n",
      "1.0.2\n",
      "2.5.0\n",
      "2.5.0\n",
      "Sat Apr 29 20:15:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:07.0 Off |                  Off |\n",
      "| N/A   29C    P8    11W /  70W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3878ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "cols=\"\"\"duration,\n",
    "protocol_type,\n",
    "service,\n",
    "flag,\n",
    "src_bytes,\n",
    "dst_bytes,\n",
    "land,\n",
    "wrong_fragment,\n",
    "urgent,\n",
    "hot,\n",
    "num_failed_logins,\n",
    "logged_in,\n",
    "num_compromised,\n",
    "root_shell,\n",
    "su_attempted,\n",
    "num_root,\n",
    "num_file_creations,\n",
    "num_shells,\n",
    "num_access_files,\n",
    "num_outbound_cmds,\n",
    "is_host_login,\n",
    "is_guest_login,\n",
    "count,\n",
    "srv_count,\n",
    "serror_rate,\n",
    "srv_serror_rate,\n",
    "rerror_rate,\n",
    "srv_rerror_rate,\n",
    "same_srv_rate,\n",
    "diff_srv_rate,\n",
    "srv_diff_host_rate,\n",
    "dst_host_count,\n",
    "dst_host_srv_count,\n",
    "dst_host_same_srv_rate,\n",
    "dst_host_diff_srv_rate,\n",
    "dst_host_same_src_port_rate,\n",
    "dst_host_srv_diff_host_rate,\n",
    "dst_host_serror_rate,\n",
    "dst_host_srv_serror_rate,\n",
    "dst_host_rerror_rate,\n",
    "dst_host_srv_rerror_rate\"\"\"\n",
    "\n",
    "columns=[]\n",
    "for c in cols.split(','):\n",
    "    if(c.strip()):\n",
    "       columns.append(c.strip())\n",
    "\n",
    "columns.append('target')\n",
    "#print(columns)\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58c09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks_types = {\n",
    "    'normal': 'normal',\n",
    "'back': 'dos',\n",
    "'buffer_overflow': 'u2r',\n",
    "'ftp_write': 'r2l',\n",
    "'guess_passwd': 'r2l',\n",
    "'imap': 'r2l',\n",
    "'ipsweep': 'probe',\n",
    "'land': 'dos',\n",
    "'loadmodule': 'u2r',\n",
    "'multihop': 'r2l',\n",
    "'neptune': 'dos',\n",
    "'nmap': 'probe',\n",
    "'perl': 'u2r',\n",
    "'phf': 'r2l',\n",
    "'pod': 'dos',\n",
    "'portsweep': 'probe',\n",
    "'rootkit': 'u2r',\n",
    "'satan': 'probe',\n",
    "'smurf': 'dos',\n",
    "'spy': 'r2l',\n",
    "'teardrop': 'dos',\n",
    "'warezclient': 'r2l',\n",
    "'warezmaster': 'r2l',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6737445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>target</th>\n",
       "      <th>Attack Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        215      45076     0   \n",
       "1         0           tcp    http   SF        162       4528     0   \n",
       "2         0           tcp    http   SF        236       1228     0   \n",
       "3         0           tcp    http   SF        233       2032     0   \n",
       "4         0           tcp    http   SF        239        486     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                     0.0   \n",
       "1               0       0    0  ...                     1.0   \n",
       "2               0       0    0  ...                     1.0   \n",
       "3               0       0    0  ...                     1.0   \n",
       "4               0       0    0  ...                     1.0   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                     0.0                         0.00   \n",
       "1                     0.0                         1.00   \n",
       "2                     0.0                         0.50   \n",
       "3                     0.0                         0.33   \n",
       "4                     0.0                         0.25   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                          0.0                   0.0   \n",
       "1                          0.0                   0.0   \n",
       "2                          0.0                   0.0   \n",
       "3                          0.0                   0.0   \n",
       "4                          0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                   0.0                       0.0   \n",
       "1                       0.0                   0.0                       0.0   \n",
       "2                       0.0                   0.0                       0.0   \n",
       "3                       0.0                   0.0                       0.0   \n",
       "4                       0.0                   0.0                       0.0   \n",
       "\n",
       "    target  Attack Type  \n",
       "0  normal.       normal  \n",
       "1  normal.       normal  \n",
       "2  normal.       normal  \n",
       "3  normal.       normal  \n",
       "4  normal.       normal  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = \"../../../kddcup.data\"\n",
    "path2 = \"../../../kddcup.data_10_percent\"\n",
    "df = pd.read_csv(path1,names=columns)\n",
    "\n",
    "#Adding Attack Type column\n",
    "df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678c462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48085/1196107924.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only\n",
      "  df = df.dropna('columns')# drop columns with NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898431, 31)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna('columns')# drop columns with NaN\n",
    "df = df[[col for col in df if df[col].nunique() > 1]]# keep columns where there are more than 1 unique values\n",
    "\n",
    "df.drop('num_root',axis = 1,inplace = True)\n",
    "df.drop('srv_serror_rate',axis = 1,inplace = True)\n",
    "df.drop('srv_rerror_rate',axis = 1, inplace=True)\n",
    "df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)\n",
    "df.drop('dst_host_serror_rate',axis = 1, inplace=True)\n",
    "df.drop('dst_host_rerror_rate',axis = 1, inplace=True)\n",
    "df.drop('dst_host_srv_rerror_rate',axis = 1, inplace=True)\n",
    "df.drop('dst_host_same_srv_rate',axis = 1, inplace=True)\n",
    "\n",
    "df.drop('is_host_login',axis = 1, inplace=True)\n",
    "\n",
    "#protocol_type feature mapping\n",
    "pmap = {'icmp':0,'tcp':1,'udp':2}\n",
    "df['protocol_type'] = df['protocol_type'].map(pmap)\n",
    "\n",
    "#flag feature mapping\n",
    "fmap = {'SF':0,'S0':1,'REJ':2,'RSTR':3,'RSTO':4,'SH':5 ,'S1':6 ,'S2':7,'RSTOS0':8,'S3':9 ,'OTH':10}\n",
    "df['flag'] = df['flag'].map(fmap)\n",
    "\n",
    "#attack type feature mapping\n",
    "amap = {'dos':0,'normal':1,'probe':2,'r2l':3,'u2r':4}\n",
    "df['Attack Type'] = df['Attack Type'].map(amap)\n",
    "\n",
    "df.drop('service',axis = 1,inplace= True)\n",
    "\n",
    "df = df.drop(['target',], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3809eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3281948, 30) (1616483, 30)\n",
      "(3281948, 1) (1616483, 1)\n"
     ]
    }
   ],
   "source": [
    "# Target variable and train set\n",
    "Y = df[['Attack Type']]\n",
    "X = df.drop(['Attack Type',], axis=1)\n",
    "batch_size=64\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Split test and train data \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a05dca",
   "metadata": {},
   "source": [
    "## Attention CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afea48",
   "metadata": {},
   "source": [
    "### Attention_CNN2(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3160021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 20:15:53.521104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-29 20:15:53.543072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.544210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 15.74GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-04-29 20:15:53.544271: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-29 20:15:53.547645: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-29 20:15:53.547744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-04-29 20:15:53.548761: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-29 20:15:53.549106: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-29 20:15:53.550002: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-04-29 20:15:53.550751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-04-29 20:15:53.550963: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-29 20:15:53.551085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.551432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.551688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-04-29 20:15:53.552138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 20:15:53.553452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.553761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 15.74GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2023-04-29 20:15:53.553873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.554180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:53.554450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-04-29 20:15:53.554501: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-04-29 20:15:54.066878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-29 20:15:54.066898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-04-29 20:15:54.066903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-04-29 20:15:54.067115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:54.067502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:54.067800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 20:15:54.068076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14812 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 64)       256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 15, 64)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 15, 128)      24704       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 7, 128)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 896)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          114816      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 128)          0           batch_normalization[0][0]        \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            325         batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 165,637\n",
      "Trainable params: 165,253\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 20:15:54.994284: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-04-29 20:15:54.994746: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2999760000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 20:15:55.750816: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-04-29 20:15:56.285141: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2023-04-29 20:15:56.918067: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-04-29 20:15:57.340078: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51281/51281 [==============================] - 152s 3ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 150s 3ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 152s 3ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 150s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 149s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 150s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Training time:  1507.8110387325287\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(30, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "attention_layer1 = attention_layer(bn_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "bn_layer2 = BatchNormalization()(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(bn_layer2)\n",
    "attention_cnn2bn_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn2bn_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn2bn_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn2bn_model.fit(X_train.reshape((-1,30,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn2bn_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn2bn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1481cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn2bn_model\n",
      "Training Accuracy: 0.9996876854843526\n",
      "Testing Accuracy: 0.999612739509169\n",
      "Training f1: 0.852972854380087\n",
      "Testing f1: 0.8286464584400639\n",
      "Training recall: 0.8290413474024495\n",
      "Testing recall: 0.8068572856283784\n"
     ]
    }
   ],
   "source": [
    "attention_cnn2bn_preds_train = attention_cnn2bn_model.predict(X_train.reshape((-1,30,1)))\n",
    "attention_cnn2bn_test = attention_cnn2bn_model.predict(X_test.reshape((-1,30,1)))\n",
    "print(\"attention_cnn2bn_model\")\n",
    "attention_cnn2bn_train_acc = accuracy_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1))\n",
    "attention_cnn2bn_test_acc = accuracy_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1))\n",
    "attention_cnn2bn_train_f1 = f1_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1), average='macro')\n",
    "attention_cnn2bn_test_f1 = f1_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1), average='macro')\n",
    "attention_cnn2bn_train_recall = recall_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1), average='macro')\n",
    "attention_cnn2bn_test_recall = recall_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn2bn_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn2bn_test_acc)\n",
    "print(\"Training f1:\", attention_cnn2bn_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn2bn_test_f1)\n",
    "print(\"Training recall:\", attention_cnn2bn_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn2bn_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8044f1",
   "metadata": {},
   "source": [
    "## 改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fc446",
   "metadata": {},
   "source": [
    "### Attention_CNN3(dropout1==0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472b76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 30, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 64)       256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 15, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 15, 128)      24704       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 7, 128)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 896)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          114816      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128)          0           dropout[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5)            325         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 165,381\n",
      "Trainable params: 165,125\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0065 - accuracy: 0.9988\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 135s 3ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Training time:  1364.2454171180725\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(30, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "dropout_layer1 = Dropout(0.01)(bn_layer1)\n",
    "attention_layer1 = attention_layer(dropout_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "dropout_layer2 = Dropout(0.01)(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(dropout_layer2)\n",
    "attention_cnn3dropout1_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn3dropout1_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn3dropout1_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn3dropout1_model.fit(X_train.reshape((-1,30,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn3dropout1_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn3dropout1_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fdb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn3dropout1_model\n",
      "Training Accuracy: 0.999694998214475\n",
      "Testing Accuracy: 0.9996207816599371\n",
      "Training f1: 0.7546841142258833\n",
      "Testing f1: 0.7494464146120455\n",
      "Training recall: 0.7474162876668743\n",
      "Testing recall: 0.7472531478720398\n"
     ]
    }
   ],
   "source": [
    "cnn3dropout1_preds_train = attention_cnn3dropout1_model.predict(X_train.reshape((-1,30,1)))\n",
    "cnn3dropout1_test = attention_cnn3dropout1_model.predict(X_test.reshape((-1,30,1)))\n",
    "print(\"attention_cnn3dropout1_model\")\n",
    "attention_cnn3dropout1_train_acc = accuracy_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1))\n",
    "attention_cnn3dropout1_test_acc = accuracy_score(Y_test, np.argmax(cnn3dropout1_test, axis=1))\n",
    "attention_cnn3dropout1_train_f1 = f1_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout1_test_f1 = f1_score(Y_test, np.argmax(cnn3dropout1_test, axis=1), average='macro')\n",
    "attention_cnn3dropout1_train_recall = recall_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout1_test_recall = recall_score(Y_test, np.argmax(cnn3dropout1_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn3dropout1_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn3dropout1_test_acc)\n",
    "print(\"Training f1:\", attention_cnn3dropout1_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn3dropout1_test_f1)\n",
    "print(\"Training recall:\", attention_cnn3dropout1_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn3dropout1_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5ea60",
   "metadata": {},
   "source": [
    "### Attention_CNN3(dropout2==0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99873f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 30, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 30, 64)       256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 15, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 15, 128)      24704       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 7, 128)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 896)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          114816      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 128)          0           dropout_2[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           8256        multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5)            325         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 165,381\n",
      "Trainable params: 165,125\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0066 - accuracy: 0.9988\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 136s 3ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 137s 3ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Training time:  1373.9966311454773\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(30, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "dropout_layer1 = Dropout(0.01)(bn_layer1)\n",
    "attention_layer1 = attention_layer(dropout_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "dropout_layer2 = Dropout(0.01)(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(dropout_layer2)\n",
    "attention_cnn3dropout2_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn3dropout2_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn3dropout2_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn3dropout2_model.fit(X_train.reshape((-1,30,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn3dropout2_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn3dropout2_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6578c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn3dropout2_model\n",
      "Training Accuracy: 0.9996291836433728\n",
      "Testing Accuracy: 0.9995756218902395\n",
      "Training f1: 0.7483151476064495\n",
      "Testing f1: 0.7463092866496739\n",
      "Training recall: 0.7465699444361118\n",
      "Testing recall: 0.7519383077170098\n"
     ]
    }
   ],
   "source": [
    "cnn3dropout2_preds_train = attention_cnn3dropout2_model.predict(X_train.reshape((-1,30,1)))\n",
    "cnn3dropout2_test = attention_cnn3dropout2_model.predict(X_test.reshape((-1,30,1)))\n",
    "print(\"attention_cnn3dropout2_model\")\n",
    "attention_cnn3dropout2_train_acc = accuracy_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1))\n",
    "attention_cnn3dropout2_test_acc = accuracy_score(Y_test, np.argmax(cnn3dropout2_test, axis=1))\n",
    "attention_cnn3dropout2_train_f1 = f1_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout2_test_f1 = f1_score(Y_test, np.argmax(cnn3dropout2_test, axis=1), average='macro')\n",
    "attention_cnn3dropout2_train_recall = recall_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout2_test_recall = recall_score(Y_test, np.argmax(cnn3dropout2_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn3dropout2_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn3dropout2_test_acc)\n",
    "print(\"Training f1:\", attention_cnn3dropout2_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn3dropout2_test_f1)\n",
    "print(\"Training recall:\", attention_cnn3dropout2_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn3dropout2_test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6cbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = {\"attention_cnn2bn_train_acc\":attention_cnn2bn_train_acc, \n",
    "            \"attention_cnn3dropout1_train_acc\":attention_cnn3dropout1_train_acc, \"attention_cnn3dropout2_train_acc\":attention_cnn3dropout2_train_acc}\n",
    "test_acc = {\"attention_cnn2bn_test_acc\":attention_cnn2bn_test_acc,\n",
    "            \"attention_cnn3dropout1_test_acc\":attention_cnn3dropout1_test_acc, \"attention_cnn3dropout2_test_acc\":attention_cnn3dropout2_test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc757e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = {\"attention_cnn2bn_train_f1\":attention_cnn2bn_train_f1, \n",
    "            \"attention_cnn3dropout1_train_f1\":attention_cnn3dropout1_train_f1, \"attention_cnn3dropout2_train_f1\":attention_cnn3dropout2_train_f1}\n",
    "test_f1 = {\"attention_cnn2bn_test_f1\":attention_cnn2bn_test_f1, \n",
    "            \"attention_cnn3dropout1_test_f1\":attention_cnn3dropout1_test_f1, \"attention_cnn3dropout2_test_f1\":attention_cnn3dropout2_test_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a2b67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall = {\"attention_cnn2bn_train_recall\":attention_cnn2bn_train_recall, \n",
    "            \"attention_cnn3dropout1_train_recall\":attention_cnn3dropout1_train_recall, \"attention_cnn3dropout2_train_recall\":attention_cnn3dropout2_train_recall}\n",
    "test_recall = {\"attention_cnn2bn_test_recall\":attention_cnn2bn_test_recall, \n",
    "            \"attention_cnn3dropout1_test_recall\":attention_cnn3dropout1_test_recall, \"attention_cnn3dropout2_test_recall\":attention_cnn3dropout2_test_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b66fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_cnn2bn_train_acc': 0.9996876854843526, 'attention_cnn3dropout1_train_acc': 0.999694998214475, 'attention_cnn3dropout2_train_acc': 0.9996291836433728}\n",
      "{'attention_cnn2bn_test_acc': 0.999612739509169, 'attention_cnn3dropout1_test_acc': 0.9996207816599371, 'attention_cnn3dropout2_test_acc': 0.9995756218902395}\n",
      "{'attention_cnn2bn_train_f1': 0.852972854380087, 'attention_cnn3dropout1_train_f1': 0.7546841142258833, 'attention_cnn3dropout2_train_f1': 0.7483151476064495}\n",
      "{'attention_cnn2bn_test_f1': 0.8286464584400639, 'attention_cnn3dropout1_test_f1': 0.7494464146120455, 'attention_cnn3dropout2_test_f1': 0.7463092866496739}\n",
      "{'attention_cnn2bn_train_recall': 0.8290413474024495, 'attention_cnn3dropout1_train_recall': 0.7474162876668743, 'attention_cnn3dropout2_train_recall': 0.7465699444361118}\n",
      "{'attention_cnn2bn_test_recall': 0.8068572856283784, 'attention_cnn3dropout1_test_recall': 0.7472531478720398, 'attention_cnn3dropout2_test_recall': 0.7519383077170098}\n"
     ]
    }
   ],
   "source": [
    "print(train_acc, test_acc, train_f1, test_f1, train_recall, test_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f379e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_to_txt(dic, filepath):\n",
    "    # 遍历字典的元素，将每项元素的key和value分拆组成字符串，注意添加分隔符和换行符\n",
    "    file = open(filepath, 'w')\n",
    "    for k, v in dic.items():\n",
    "        file.write(str(k) + ' ' + str(v) + '\\n')\n",
    "\n",
    "    # 注意关闭文件\n",
    "    file.close()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ccd9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_acc, './AttentionCNN_reduce_train_acc.txt')\n",
    "dic_to_txt(test_acc, './AttentionCNN_reduce_test_acc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa3a0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_f1, './AttentionCNN_reduce_train_f1.txt')\n",
    "dic_to_txt(test_f1, './AttentionCNN_reduce_test_f1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d653cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_recall, './AttentionCNN_reduce_train_recall.txt')\n",
    "dic_to_txt(test_recall, './AttentionCNN_reduce_test_recall.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38479b2f-11cb-4ee1-86ae-6db4ba5557af",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7018c4-afe6-4ca1-a233-f15a745c9f48",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215b6a6-9100-431e-89a1-4688f60deb23",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "502b7c92-58fc-4b3b-ab18-2d7b57d7f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Softmax, Multiply, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2dca1c4-4d6d-4c25-a988-d661a92a774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.4\n",
      "1.19.5\n",
      "3.4.3\n",
      "1.0.2\n",
      "2.5.0\n",
      "2.5.0\n",
      "Sat Apr 29 21:33:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:07.0 Off |                  Off |\n",
      "| N/A   40C    P0    29W /  70W |  15641MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddae25f9-e42b-4a83-9771-e511110ef4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "cols=\"\"\"duration,\n",
    "protocol_type,\n",
    "service,\n",
    "flag,\n",
    "src_bytes,\n",
    "dst_bytes,\n",
    "land,\n",
    "wrong_fragment,\n",
    "urgent,\n",
    "hot,\n",
    "num_failed_logins,\n",
    "logged_in,\n",
    "num_compromised,\n",
    "root_shell,\n",
    "su_attempted,\n",
    "num_root,\n",
    "num_file_creations,\n",
    "num_shells,\n",
    "num_access_files,\n",
    "num_outbound_cmds,\n",
    "is_host_login,\n",
    "is_guest_login,\n",
    "count,\n",
    "srv_count,\n",
    "serror_rate,\n",
    "srv_serror_rate,\n",
    "rerror_rate,\n",
    "srv_rerror_rate,\n",
    "same_srv_rate,\n",
    "diff_srv_rate,\n",
    "srv_diff_host_rate,\n",
    "dst_host_count,\n",
    "dst_host_srv_count,\n",
    "dst_host_same_srv_rate,\n",
    "dst_host_diff_srv_rate,\n",
    "dst_host_same_src_port_rate,\n",
    "dst_host_srv_diff_host_rate,\n",
    "dst_host_serror_rate,\n",
    "dst_host_srv_serror_rate,\n",
    "dst_host_rerror_rate,\n",
    "dst_host_srv_rerror_rate\"\"\"\n",
    "\n",
    "columns=[]\n",
    "for c in cols.split(','):\n",
    "    if(c.strip()):\n",
    "       columns.append(c.strip())\n",
    "\n",
    "columns.append('target')\n",
    "#print(columns)\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "374951f9-7d52-4e2f-b3e3-89d7fb77df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks_types = {\n",
    "    'normal': 'normal',\n",
    "'back': 'dos',\n",
    "'buffer_overflow': 'u2r',\n",
    "'ftp_write': 'r2l',\n",
    "'guess_passwd': 'r2l',\n",
    "'imap': 'r2l',\n",
    "'ipsweep': 'probe',\n",
    "'land': 'dos',\n",
    "'loadmodule': 'u2r',\n",
    "'multihop': 'r2l',\n",
    "'neptune': 'dos',\n",
    "'nmap': 'probe',\n",
    "'perl': 'u2r',\n",
    "'phf': 'r2l',\n",
    "'pod': 'dos',\n",
    "'portsweep': 'probe',\n",
    "'rootkit': 'u2r',\n",
    "'satan': 'probe',\n",
    "'smurf': 'dos',\n",
    "'spy': 'r2l',\n",
    "'teardrop': 'dos',\n",
    "'warezclient': 'r2l',\n",
    "'warezmaster': 'r2l',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf4a1e4b-a1f8-46d6-aa2e-c48711bfc2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>target</th>\n",
       "      <th>Attack Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        215      45076     0   \n",
       "1         0           tcp    http   SF        162       4528     0   \n",
       "2         0           tcp    http   SF        236       1228     0   \n",
       "3         0           tcp    http   SF        233       2032     0   \n",
       "4         0           tcp    http   SF        239        486     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                     0.0   \n",
       "1               0       0    0  ...                     1.0   \n",
       "2               0       0    0  ...                     1.0   \n",
       "3               0       0    0  ...                     1.0   \n",
       "4               0       0    0  ...                     1.0   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                     0.0                         0.00   \n",
       "1                     0.0                         1.00   \n",
       "2                     0.0                         0.50   \n",
       "3                     0.0                         0.33   \n",
       "4                     0.0                         0.25   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                          0.0                   0.0   \n",
       "1                          0.0                   0.0   \n",
       "2                          0.0                   0.0   \n",
       "3                          0.0                   0.0   \n",
       "4                          0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                   0.0                       0.0   \n",
       "1                       0.0                   0.0                       0.0   \n",
       "2                       0.0                   0.0                       0.0   \n",
       "3                       0.0                   0.0                       0.0   \n",
       "4                       0.0                   0.0                       0.0   \n",
       "\n",
       "    target  Attack Type  \n",
       "0  normal.       normal  \n",
       "1  normal.       normal  \n",
       "2  normal.       normal  \n",
       "3  normal.       normal  \n",
       "4  normal.       normal  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = \"../../../kddcup.data\"\n",
    "path2 = \"../../../kddcup.data_10_percent\"\n",
    "df = pd.read_csv(path1,names=columns)\n",
    "\n",
    "#Adding Attack Type column\n",
    "df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a25145b-36b4-4ce6-8ba6-f797b8c9d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48085/4268764986.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only\n",
      "  df = df.dropna('columns')# drop columns with NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898431, 40)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna('columns')# drop columns with NaN\n",
    "df = df[[col for col in df if df[col].nunique() > 1]]# keep columns where there are more than 1 unique values\n",
    "\n",
    "# df.drop('num_root',axis = 1,inplace = True)\n",
    "# df.drop('srv_serror_rate',axis = 1,inplace = True)\n",
    "# df.drop('srv_rerror_rate',axis = 1, inplace=True)\n",
    "# df.drop('dst_host_srv_serror_rate',axis = 1, inplace=True)\n",
    "# df.drop('dst_host_serror_rate',axis = 1, inplace=True)\n",
    "# df.drop('dst_host_rerror_rate',axis = 1, inplace=True)\n",
    "# df.drop('dst_host_srv_rerror_rate',axis = 1, inplace=True)\n",
    "# df.drop('dst_host_same_srv_rate',axis = 1, inplace=True)\n",
    "\n",
    "# df.drop('is_host_login',axis = 1, inplace=True)\n",
    "\n",
    "#protocol_type feature mapping\n",
    "pmap = {'icmp':0,'tcp':1,'udp':2}\n",
    "df['protocol_type'] = df['protocol_type'].map(pmap)\n",
    "\n",
    "#flag feature mapping\n",
    "fmap = {'SF':0,'S0':1,'REJ':2,'RSTR':3,'RSTO':4,'SH':5 ,'S1':6 ,'S2':7,'RSTOS0':8,'S3':9 ,'OTH':10}\n",
    "df['flag'] = df['flag'].map(fmap)\n",
    "\n",
    "#attack type feature mapping\n",
    "amap = {'dos':0,'normal':1,'probe':2,'r2l':3,'u2r':4}\n",
    "df['Attack Type'] = df['Attack Type'].map(amap)\n",
    "\n",
    "df.drop('service',axis = 1,inplace= True)\n",
    "\n",
    "df = df.drop(['target',], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f5c44f7-9871-4ba3-843a-c25f98cfead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3281948, 39) (1616483, 39)\n",
      "(3281948, 1) (1616483, 1)\n"
     ]
    }
   ],
   "source": [
    "# Target variable and train set\n",
    "Y = df[['Attack Type']]\n",
    "X = df.drop(['Attack Type',], axis=1)\n",
    "batch_size=batch_size\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Split test and train data \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cffc86-3032-4bab-9a9c-26cf18431866",
   "metadata": {},
   "source": [
    "## Unprocessed Attention CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744b97b-ad42-488c-b3a0-3d0729fcf399",
   "metadata": {},
   "source": [
    "### Attention_CNN2(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa487f5e-7324-442a-a9dd-520b0902d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 39, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 39, 64)       256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 19, 64)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 19, 128)      24704       max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 9, 128)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 1152)         0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          147584      flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 128)          0           batch_normalization_4[0][0]      \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           8256        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64)           256         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 5)            325         batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 198,405\n",
      "Trainable params: 198,021\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 153s 3ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 152s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 152s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 152s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 150s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 153s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 151s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 153s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 154s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Training time:  1521.8959438800812\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(39, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "attention_layer1 = attention_layer(bn_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "bn_layer2 = BatchNormalization()(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(bn_layer2)\n",
    "attention_cnn2bn_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn2bn_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn2bn_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn2bn_model.fit(X_train.reshape((-1,39,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn2bn_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn2bn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1993e98-24ff-48ae-9622-2aeb047a4ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn2bn_model\n",
      "Training Accuracy: 0.9997178504961078\n",
      "Testing Accuracy: 0.9996783139692778\n",
      "Training f1: 0.7548793939128742\n",
      "Testing f1: 0.7543989859493948\n",
      "Training recall: 0.7485729355482988\n",
      "Testing recall: 0.7473104492306442\n"
     ]
    }
   ],
   "source": [
    "attention_cnn2bn_preds_train = attention_cnn2bn_model.predict(X_train.reshape((-1,39,1)))\n",
    "attention_cnn2bn_test = attention_cnn2bn_model.predict(X_test.reshape((-1,39,1)))\n",
    "print(\"attention_cnn2bn_model\")\n",
    "attention_cnn2bn_train_acc = accuracy_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1))\n",
    "attention_cnn2bn_test_acc = accuracy_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1))\n",
    "attention_cnn2bn_train_f1 = f1_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1), average='macro')\n",
    "attention_cnn2bn_test_f1 = f1_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1), average='macro')\n",
    "attention_cnn2bn_train_recall = recall_score(Y_train, np.argmax(attention_cnn2bn_preds_train, axis=1), average='macro')\n",
    "attention_cnn2bn_test_recall = recall_score(Y_test, np.argmax(attention_cnn2bn_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn2bn_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn2bn_test_acc)\n",
    "print(\"Training f1:\", attention_cnn2bn_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn2bn_test_f1)\n",
    "print(\"Training recall:\", attention_cnn2bn_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn2bn_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12968798-8691-497d-aea7-247eac24a86a",
   "metadata": {},
   "source": [
    "## 改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b408b-38ce-47a1-b4ff-0e5d9ea81f7d",
   "metadata": {},
   "source": [
    "### Attention_CNN3(dropout1==0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c18cbc4c-0717-4329-a999-1c2bfa879eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 39, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 39, 64)       256         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 19, 64)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 19, 128)      24704       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 9, 128)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1152)         0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          147584      flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128)          512         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          16512       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 128)          0           dropout_4[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           8256        multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 5)            325         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 198,149\n",
      "Trainable params: 197,893\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51281/51281 [==============================] - 139s 3ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 142s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 140s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 140s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 140s 3ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 139s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 166s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 165s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Training time:  1448.6793644428253\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(39, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "dropout_layer1 = Dropout(0.01)(bn_layer1)\n",
    "attention_layer1 = attention_layer(dropout_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "dropout_layer2 = Dropout(0.01)(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(dropout_layer2)\n",
    "attention_cnn3dropout1_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn3dropout1_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn3dropout1_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn3dropout1_model.fit(X_train.reshape((-1,39,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn3dropout1_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn3dropout1_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e77aac97-43a6-4ab1-95cb-485ab52c59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn3dropout1_model\n",
      "Training Accuracy: 0.9997620315739311\n",
      "Testing Accuracy: 0.9997154315882072\n",
      "Training f1: 0.7545396606558306\n",
      "Testing f1: 0.7457175900173778\n",
      "Training recall: 0.7334947908965008\n",
      "Testing recall: 0.7243159901571472\n"
     ]
    }
   ],
   "source": [
    "cnn3dropout1_preds_train = attention_cnn3dropout1_model.predict(X_train.reshape((-1,39,1)))\n",
    "cnn3dropout1_test = attention_cnn3dropout1_model.predict(X_test.reshape((-1,39,1)))\n",
    "print(\"attention_cnn3dropout1_model\")\n",
    "attention_cnn3dropout1_train_acc = accuracy_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1))\n",
    "attention_cnn3dropout1_test_acc = accuracy_score(Y_test, np.argmax(cnn3dropout1_test, axis=1))\n",
    "attention_cnn3dropout1_train_f1 = f1_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout1_test_f1 = f1_score(Y_test, np.argmax(cnn3dropout1_test, axis=1), average='macro')\n",
    "attention_cnn3dropout1_train_recall = recall_score(Y_train, np.argmax(cnn3dropout1_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout1_test_recall = recall_score(Y_test, np.argmax(cnn3dropout1_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn3dropout1_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn3dropout1_test_acc)\n",
    "print(\"Training f1:\", attention_cnn3dropout1_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn3dropout1_test_f1)\n",
    "print(\"Training recall:\", attention_cnn3dropout1_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn3dropout1_test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b774d-464b-4a91-95ef-c1f776ee2a6a",
   "metadata": {},
   "source": [
    "### Attention_CNN3(dropout2==0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "999328b2-3b1f-4b9c-8ebf-becc0c2fe38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 39, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 39, 64)       256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 19, 64)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 19, 128)      24704       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 9, 128)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1152)         0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          147584      flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          16512       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 128)          0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 128)          0           dropout_6[0][0]                  \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           8256        multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 5)            325         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 198,149\n",
      "Trainable params: 197,893\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "51281/51281 [==============================] - 163s 3ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "51281/51281 [==============================] - 163s 3ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 3/10\n",
      "51281/51281 [==============================] - 164s 3ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "51281/51281 [==============================] - 166s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 5/10\n",
      "51281/51281 [==============================] - 170s 3ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "51281/51281 [==============================] - 162s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 7/10\n",
      "51281/51281 [==============================] - 142s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "51281/51281 [==============================] - 141s 3ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 9/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "51281/51281 [==============================] - 138s 3ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Training time:  1546.743384361267\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, BatchNormalization, GlobalMaxPooling1D\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    attention_weights = Dense(units=128, activation='softmax')(inputs)\n",
    "    attention_weights = Flatten()(attention_weights)\n",
    "    attention_weights = Multiply()([inputs, attention_weights])\n",
    "    return attention_weights\n",
    "\n",
    "input_layer = Input(shape=(39, 1))\n",
    "conv_layer1 = Conv1D(64, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "pool_layer1 = MaxPooling1D(pool_size=(2))(conv_layer1)\n",
    "conv_layer2 = Conv1D(128, 3, padding=\"same\", activation=\"relu\")(pool_layer1)\n",
    "pool_layer2 = MaxPooling1D(pool_size=(2))(conv_layer2)\n",
    "flatten_layer = Flatten()(pool_layer2)\n",
    "dense_layer1 = Dense(128, activation=\"relu\")(flatten_layer)\n",
    "bn_layer1 = BatchNormalization()(dense_layer1)\n",
    "dropout_layer1 = Dropout(0.01)(bn_layer1)\n",
    "attention_layer1 = attention_layer(dropout_layer1)\n",
    "dense_layer2 = Dense(64, activation=\"relu\")(attention_layer1)\n",
    "dropout_layer2 = Dropout(0.01)(dense_layer2)\n",
    "output_layer = Dense(5, activation=\"softmax\")(dropout_layer2)\n",
    "attention_cnn3dropout2_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "attention_cnn3dropout2_model.compile(loss ='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(attention_cnn3dropout2_model.summary())\n",
    "start_time = time.time()\n",
    "attention_cnn3dropout2_model.fit(X_train.reshape((-1,39,1)), Y_train.values.ravel(), epochs=10, batch_size=batch_size)\n",
    "end_time = time.time()\n",
    "attention_cnn3dropout2_time = end_time-start_time\n",
    "print(\"Training time: \", attention_cnn3dropout2_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c8abe0-80f1-4da8-a65c-0729bca2fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_cnn3dropout2_model\n",
      "Training Accuracy: 0.9997879308264482\n",
      "Testing Accuracy: 0.9997432698024044\n",
      "Training f1: 0.8847560348459765\n",
      "Testing f1: 0.8636587401261986\n",
      "Training recall: 0.8786176572957356\n",
      "Testing recall: 0.8414356841924169\n"
     ]
    }
   ],
   "source": [
    "cnn3dropout2_preds_train = attention_cnn3dropout2_model.predict(X_train.reshape((-1,39,1)))\n",
    "cnn3dropout2_test = attention_cnn3dropout2_model.predict(X_test.reshape((-1,39,1)))\n",
    "print(\"attention_cnn3dropout2_model\")\n",
    "attention_cnn3dropout2_train_acc = accuracy_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1))\n",
    "attention_cnn3dropout2_test_acc = accuracy_score(Y_test, np.argmax(cnn3dropout2_test, axis=1))\n",
    "attention_cnn3dropout2_train_f1 = f1_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout2_test_f1 = f1_score(Y_test, np.argmax(cnn3dropout2_test, axis=1), average='macro')\n",
    "attention_cnn3dropout2_train_recall = recall_score(Y_train, np.argmax(cnn3dropout2_preds_train, axis=1), average='macro')\n",
    "attention_cnn3dropout2_test_recall = recall_score(Y_test, np.argmax(cnn3dropout2_test, axis=1), average='macro')\n",
    "print(\"Training Accuracy:\", attention_cnn3dropout2_train_acc)\n",
    "print(\"Testing Accuracy:\", attention_cnn3dropout2_test_acc)\n",
    "print(\"Training f1:\", attention_cnn3dropout2_train_f1)\n",
    "print(\"Testing f1:\", attention_cnn3dropout2_test_f1)\n",
    "print(\"Training recall:\", attention_cnn3dropout2_train_recall)\n",
    "print(\"Testing recall:\", attention_cnn3dropout2_test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d352b7a5-4c9d-4de3-b0a5-e413337a4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = {\"attention_cnn2bn_train_acc\":attention_cnn2bn_train_acc, \n",
    "            \"attention_cnn3dropout1_train_acc\":attention_cnn3dropout1_train_acc, \"attention_cnn3dropout2_train_acc\":attention_cnn3dropout2_train_acc}\n",
    "test_acc = {\"attention_cnn2bn_test_acc\":attention_cnn2bn_test_acc,\n",
    "            \"attention_cnn3dropout1_test_acc\":attention_cnn3dropout1_test_acc, \"attention_cnn3dropout2_test_acc\":attention_cnn3dropout2_test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23de301b-4ca3-4b97-8327-cd54996930a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = {\"attention_cnn2bn_train_f1\":attention_cnn2bn_train_f1, \n",
    "            \"attention_cnn3dropout1_train_f1\":attention_cnn3dropout1_train_f1, \"attention_cnn3dropout2_train_f1\":attention_cnn3dropout2_train_f1}\n",
    "test_f1 = {\"attention_cnn2bn_test_f1\":attention_cnn2bn_test_f1, \n",
    "            \"attention_cnn3dropout1_test_f1\":attention_cnn3dropout1_test_f1, \"attention_cnn3dropout2_test_f1\":attention_cnn3dropout2_test_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ffd97a0-fe9c-4920-a0bf-6a068c1e4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall = {\"attention_cnn2bn_train_recall\":attention_cnn2bn_train_recall, \n",
    "            \"attention_cnn3dropout1_train_recall\":attention_cnn3dropout1_train_recall, \"attention_cnn3dropout2_train_recall\":attention_cnn3dropout2_train_recall}\n",
    "test_recall = {\"attention_cnn2bn_test_recall\":attention_cnn2bn_test_recall, \n",
    "            \"attention_cnn3dropout1_test_recall\":attention_cnn3dropout1_test_recall, \"attention_cnn3dropout2_test_recall\":attention_cnn3dropout2_test_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b695db0a-183c-41f3-9471-4e33acbfd98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_cnn2bn_train_acc': 0.9997178504961078, 'attention_cnn3dropout1_train_acc': 0.9997620315739311, 'attention_cnn3dropout2_train_acc': 0.9997879308264482}\n",
      "{'attention_cnn2bn_test_acc': 0.9996783139692778, 'attention_cnn3dropout1_test_acc': 0.9997154315882072, 'attention_cnn3dropout2_test_acc': 0.9997432698024044}\n",
      "{'attention_cnn2bn_train_f1': 0.7548793939128742, 'attention_cnn3dropout1_train_f1': 0.7545396606558306, 'attention_cnn3dropout2_train_f1': 0.8847560348459765}\n",
      "{'attention_cnn2bn_test_f1': 0.7543989859493948, 'attention_cnn3dropout1_test_f1': 0.7457175900173778, 'attention_cnn3dropout2_test_f1': 0.8636587401261986}\n",
      "{'attention_cnn2bn_train_recall': 0.7485729355482988, 'attention_cnn3dropout1_train_recall': 0.7334947908965008, 'attention_cnn3dropout2_train_recall': 0.8786176572957356}\n",
      "{'attention_cnn2bn_test_recall': 0.7473104492306442, 'attention_cnn3dropout1_test_recall': 0.7243159901571472, 'attention_cnn3dropout2_test_recall': 0.8414356841924169}\n"
     ]
    }
   ],
   "source": [
    "print(train_acc, test_acc, train_f1, test_f1, train_recall, test_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e607e2e-9510-4073-83f2-18dfc7e4682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_to_txt(dic, filepath):\n",
    "    # 遍历字典的元素，将每项元素的key和value分拆组成字符串，注意添加分隔符和换行符\n",
    "    file = open(filepath, 'w')\n",
    "    for k, v in dic.items():\n",
    "        file.write(str(k) + ' ' + str(v) + '\\n')\n",
    "\n",
    "    # 注意关闭文件\n",
    "    file.close()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "243b8273-ada0-40a9-bfa3-436134dcd01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_acc, './unprocess_AttentionCNN_reduce_train_acc.txt')\n",
    "dic_to_txt(test_acc, './unprocess_AttentionCNN_reduce_test_acc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b8687dc-5009-4ade-857d-7ea3f4d570ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_f1, './unprocess_AttentionCNN_reduce_train_f1.txt')\n",
    "dic_to_txt(test_f1, './unprocess_AttentionCNN_reduce_test_f1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0a77df8-4967-4663-9b4b-e915650f1486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dic_to_txt(train_recall, './unprocess_AttentionCNN_reduce_train_recall.txt')\n",
    "dic_to_txt(test_recall, './unprocess_AttentionCNN_reduce_test_recall.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d64d105c-141d-4cc6-bbd9-00bfcfe9071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共耗时： 9651.361966609955\n"
     ]
    }
   ],
   "source": [
    "all_end_time = time.time()\n",
    "total_tile = all_end_time - all_start_time\n",
    "print(\"总共耗时：\", total_tile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
